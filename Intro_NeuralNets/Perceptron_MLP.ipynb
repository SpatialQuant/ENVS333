{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Iris Dataset Using The Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create our X and y data\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first five observations of the feature data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first five observations of our y data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training data and 30% test data\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(_, _, test_size = _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the scaler, which standarizes all the features to have mean=0 and unit variance\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the scaler to the X training data\n",
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "# Apply the SAME scaler to the X test data\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a perceptron object with the parameters: 40 iterations (epochs) over the data, and a learning rate of 0.1\n",
    "\n",
    "#ppn = Perceptron(max_iter=_, eta0=_, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ppn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the perceptron\n",
    "#ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the trained perceptron on the X data to make predicts for the y test data\n",
    "\n",
    "#y_pred = ppn.predict(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the predicted y test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the known y test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the accuracy of the model, which is: 1 - (observations predicted wrong / total observations) \n",
    "\n",
    "#print('Accuracy: %.2f' % accuracy_score(_, _)) #accuracy_score(known values, predicted values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pedict a new set of measurements for an observation\n",
    "\n",
    "#ppn.predict([[3.1, 5, 4.5, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert scientific notation to float value\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = MLP.predict_proba([[3,5,4,2],])\n",
    "print('the probabilities for each category are: ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the predicted species is: ')\n",
    "\n",
    "#iris.target_names[_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Iris Dataset Using a MLP Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the multi-layer perceptron with one hidden layer of 10 neurons, a sigmoid activation function\n",
    "#and using Stochastic Gradient Descent\n",
    "\n",
    "MLP = MLPClassifier(hidden_layer_sizes = (100), activation='logistic', max_iter=10000, solver='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the trained perceptron on the X data to make predicts for the y test data\n",
    "\n",
    "y_pred = MLP.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the predicted y test data\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the known y test data\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the accuracy of the model, which is: 1 - (observations predicted wrong / total observations)\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.predict([[3.1, 5, 4.5, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert scientific notation to float value\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = MLP.predict_proba([[3,5,4,2],])\n",
    "print('the probabilities for each category are: ')\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the predicted species is: ')\n",
    "iris.target_names[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Metric to Measure Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FROM SCIKIT-LEARN\n",
    "\n",
    "# Author: Rob Zinkov <rob at zinkov dot com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "heldout = [0.95, 0.90, 0.75, 0.50, 0.01]\n",
    "rounds = 5\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "classifiers = [\n",
    "    (\"Perceptron\", ___________(max_iter=400, eta0=0.1)),\n",
    "    (\"MLP\", _____________(hidden_layer_sizes = (10), activation='logistic', max_iter=10000, solver='sgd'))\n",
    "]\n",
    "\n",
    "xx = 1. - np.array(heldout)\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    print(\"training %s\" % name)\n",
    "    rng = np.random.RandomState(42)\n",
    "    yy = []\n",
    "    print(\"The cost is: \")\n",
    "    for i in heldout:\n",
    "        yy_ = []\n",
    "        for r in range(rounds):\n",
    "            X_train, X_test, y_train, y_test = \\\n",
    "                train_test_split(X, y, test_size=i, random_state=rng)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            yy_.append(1 - np.mean(y_pred == y_test))\n",
    "        yy.append(np.mean(yy_))\n",
    "    print(yy)\n",
    "    plt.plot(xx, yy, label=name)\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Proportion train\")\n",
    "plt.ylabel(\"Test Error Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
